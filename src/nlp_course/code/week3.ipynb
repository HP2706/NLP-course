{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# week 3 \n",
    "# for each language train a classifier \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "from tqdm.asyncio import tqdm as async_tqdm\n",
    "from tqdm import tqdm\n",
    "import nest_asyncio\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "nest_asyncio.apply()\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith(\"code\"):\n",
    "    os.chdir(\"..\")\n",
    "else:\n",
    "    print(\"current dir\", current_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = pd.read_parquet(\"dataset/train_df.parquet\")\n",
    "ds_val = pd.read_parquet(\"dataset/val_df.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Optional\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "class AnswerableClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int = 128,\n",
    "        expansion_factor: int = 2,\n",
    "        with_context: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        #simple linear model\n",
    "        _d_model = d_model * 2 if with_context else d_model\n",
    "        d_hidden = _d_model * expansion_factor\n",
    "        self.l_in = nn.Linear(_d_model, d_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l_out = nn.Linear(d_hidden, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l_in(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l_out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    lr: float = 1e-3\n",
    "    batch_size : int = 32\n",
    "    n_epochs : int = 10\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: TrainConfig,\n",
    "        d_model : int,\n",
    "        expansion_factor: int = 2,\n",
    "        with_context: bool = True,\n",
    "    ):\n",
    "        self.d_model = d_model\n",
    "        self.config = config\n",
    "        self.with_context = with_context\n",
    "        if with_context:\n",
    "            self.d_model *= 2\n",
    "        self.model = AnswerableClassifier(d_model, expansion_factor, with_context)\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=self.config.lr)\n",
    "        self.criterion = BCELoss()\n",
    "        self.device = get_device()\n",
    "\n",
    "    def get_batch(self, data: pd.DataFrame, with_context : bool = True) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        # we want to concatenate the question and context embeddings\n",
    "        # note that we are using matryoshka embeddings from openai \n",
    "        # so we can slice the embeddings and still get useful information\n",
    "        question_embeddings = torch.tensor(np.stack(data['question_embedding']), dtype=torch.float32, device=self.device)\n",
    "        if with_context:\n",
    "            context_embeddings = torch.tensor(np.stack(data['context_embedding']), dtype=torch.float32, device=self.device)\n",
    "            x = torch.cat(\n",
    "                (question_embeddings[:, :self.d_model], context_embeddings[:, :self.d_model]), \n",
    "                dim=1, \n",
    "            )\n",
    "        else:\n",
    "            x = question_embeddings[:, :self.d_model]\n",
    "            \n",
    "        y = torch.tensor(np.stack(data['answer_label']), device=self.device, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def fit(self, train_df: pd.DataFrame):\n",
    "        \n",
    "        total_iterations = self.config.n_epochs * len(train_df) // self.config.batch_size\n",
    "        pbar = tqdm(total=total_iterations, desc=\"Training\")\n",
    "        for epoch in range(self.config.n_epochs):\n",
    "            self.model.train()\n",
    "            self.model.to(torch.float32)\n",
    "            self.model.to(self.device)\n",
    "            \n",
    "            for batch_idx in range(0, len(train_df), self.config.batch_size):\n",
    "                data = train_df.iloc[batch_idx:batch_idx+self.config.batch_size]\n",
    "                x, y = self.get_batch(data, with_context=self.with_context)\n",
    "                pred = self.model(x)\n",
    "                loss = self.criterion(pred, y)\n",
    "                loss.backward()\n",
    "                #print(\"grad\", self.model.l_in.weight.grad)\n",
    "                self.optimizer.step()\n",
    "                pbar.update(1)\n",
    "                self.model.zero_grad()\n",
    "\n",
    "        pbar.close()\n",
    "        \n",
    "    def evaluate(self, val_df: pd.DataFrame):\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        preds = []\n",
    "        true_values = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx in range(0, len(val_df), self.config.batch_size):\n",
    "                data = val_df.iloc[batch_idx:batch_idx+self.config.batch_size]\n",
    "                x, y = self.get_batch(data, with_context=self.with_context)\n",
    "                pred = self.model(x)\n",
    "                preds.extend(pred.view(-1).cpu().numpy())\n",
    "                true_values.extend(y.view(-1).cpu().numpy())\n",
    "          \n",
    "        preds = np.array(preds).round()\n",
    "        true_values = np.array(true_values).round()\n",
    "          \n",
    "        bce_loss = self.criterion(torch.tensor(preds), torch.tensor(true_values))\n",
    "        acc = accuracy_score(true_values, preds)\n",
    "        balanced_acc = balanced_accuracy_score(true_values, preds)\n",
    "        f1 = f1_score(true_values, preds)\n",
    "        precision = precision_score(true_values, preds)\n",
    "        recall = recall_score(true_values, preds)\n",
    "        conf_matrix = confusion_matrix(true_values, preds)\n",
    "        normalized_conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'bce_loss': bce_loss,\n",
    "            'balanced_accuracy': balanced_acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'normalized_confusion_matrix': normalized_conf_matrix\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def save(self):\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        torch.save(self.model.state_dict(), \"models/model.pt\")\n",
    "\n",
    "\n",
    "def filter_language(ds: pd.DataFrame, language: str) -> pd.DataFrame:\n",
    "    return ds[ds['lang'] == language]\n",
    "\n",
    "\n",
    "train_ru = filter_language(ds_train, 'ru')\n",
    "val_ru = filter_language(ds_val, 'ru')\n",
    "train_ja = filter_language(ds_train, 'ja')\n",
    "val_ja = filter_language(ds_val, 'ja')\n",
    "train_fi = filter_language(ds_train, 'fi')\n",
    "val_fi = filter_language(ds_val, 'fi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ru with expansion factor 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Training: 620it [00:06, 94.80it/s]                         \n",
      "100%|██████████| 1/1 [00:06<00:00,  6.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for ru with expansion factor 2: {'accuracy': 0.9772727272727273, 'bce_loss': tensor(2.2727), 'balanced_accuracy': 0.7954545454545454, 'f1': 0.988110964332893, 'precision': 0.9765013054830287, 'recall': 1.0, 'confusion_matrix': array([[ 13,   9],\n",
      "       [  0, 374]]), 'normalized_confusion_matrix': array([[0.59090909, 0.40909091],\n",
      "       [0.        , 1.        ]]), 'expansion_factor': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ja with expansion factor 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Training: 720it [00:07, 94.05it/s]                         \n",
      "100%|██████████| 1/1 [00:07<00:00,  7.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for ja with expansion factor 2: {'accuracy': 0.8289473684210527, 'bce_loss': tensor(17.1053), 'balanced_accuracy': 0.524390243902439, 'f1': 0.9055690072639225, 'precision': 0.827433628318584, 'recall': 1.0, 'confusion_matrix': array([[  4,  78],\n",
      "       [  0, 374]]), 'normalized_confusion_matrix': array([[0.04878049, 0.95121951],\n",
      "       [0.        , 1.        ]]), 'expansion_factor': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fi with expansion factor 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Training: 670it [00:07, 93.40it/s]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for fi with expansion factor 2: {'accuracy': 0.9242424242424242, 'bce_loss': tensor(7.5758), 'balanced_accuracy': 0.713680387409201, 'f1': 0.9585921325051759, 'precision': 0.937246963562753, 'recall': 0.9809322033898306, 'confusion_matrix': array([[ 25,  31],\n",
      "       [  9, 463]]), 'normalized_confusion_matrix': array([[0.44642857, 0.55357143],\n",
      "       [0.0190678 , 0.9809322 ]]), 'expansion_factor': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\n    df = pd.DataFrame(lst)\\n\\n    fig = px.line(\\n        df, \\n        x='expansion_factor', \\n        y='balanced_accuracy', \\n        title=f'Accuracy for {lang}', \\n        labels={'expansion_factor': 'Expansion Factor', 'normalized_accuracy': 'Accuracy'}\\n    )\\n    fig.show() \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaling experiments\n",
    "\n",
    "expansion_factors = [2]\n",
    "\n",
    "\n",
    "for lang in ['ru', 'ja', 'fi']:\n",
    "    lst = []\n",
    "    train_ds = filter_language(ds_train, lang)\n",
    "    val_ds = filter_language(ds_val, lang)\n",
    "    for expansion_factor in tqdm(expansion_factors):\n",
    "        print(f\"Training for {lang} with expansion factor {expansion_factor}\")\n",
    "        trainer = Trainer(TrainConfig(), d_model=1536, with_context=True, expansion_factor=expansion_factor)\n",
    "        trainer.fit(train_ds)\n",
    "        metrics = trainer.evaluate(val_ds)\n",
    "        metrics['expansion_factor'] = expansion_factor\n",
    "        lst.append(metrics)\n",
    "        print(f\"Evaluation for {lang} with expansion factor {expansion_factor}: {metrics}\")\n",
    "\"\"\" \n",
    "    df = pd.DataFrame(lst)\n",
    "\n",
    "    fig = px.line(\n",
    "        df, \n",
    "        x='expansion_factor', \n",
    "        y='balanced_accuracy', \n",
    "        title=f'Accuracy for {lang}', \n",
    "        labels={'expansion_factor': 'Expansion Factor', 'normalized_accuracy': 'Accuracy'}\n",
    "    )\n",
    "    fig.show() \"\"\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
